{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(2, '/home/gaurang/glycemic_control/code/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.constants import CONTINUOUS_COVARIATES_PROCESSED, STATIC_COLS, TARGET_COL\n",
    "from src.dataset import TransformerDataset, df_to_patient_tensors, get_normalizing_scaler\n",
    "from src.models.transformer import TimeSeriesTransformer\n",
    "from src.utils import (\n",
    "    EarlyStopping,\n",
    "    generate_square_subsequent_mask,\n",
    "    get_patient_indices,\n",
    "    get_timestamp,\n",
    ")\n",
    "\n",
    "GLOBAL_SEED = 123\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_train = \"/home/gaurang/glycemic_control/data/glycaemia_project_csvs/processed_data/train_test_splits/v1_patient_split_mini/train_mini.csv\"\n",
    "fpath_valid = \"/home/gaurang/glycemic_control/data/glycaemia_project_csvs/processed_data/train_test_splits/v1_patient_split_mini/valid_mini.csv\"\n",
    "fpath_test = \"/home/gaurang/glycemic_control/data/glycaemia_project_csvs/processed_data/train_test_splits/v1_patient_split_mini/test_mini.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(fpath_train)\n",
    "df_valid = pd.read_csv(fpath_valid)\n",
    "df_test = pd.read_csv(fpath_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series params: \n",
      "Input sequence lenght: 3 \n",
      "Output sequence lenght: 1 \n",
      "Step size: 1\n",
      "Model hyperparameters: \n",
      "Batch size: 4 \n",
      "Learning rate: 0.0001\n",
      "Number of training samples: 80 \n",
      "Number of valid samples: 58 \n",
      "Number of test samples: 58\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "# Hyperparams\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "num_epochs = 20\n",
    "\n",
    "# Params\n",
    "enc_seq_len = 3  # length of input given to encoder\n",
    "output_sequence_length = 1  # how many future glucose values to predict\n",
    "step_size = 1  # Step size, i.e. how many time steps does the moving window move at each step\n",
    "batch_first = True\n",
    "\n",
    "# Define input variables\n",
    "exogenous_vars = (\n",
    "    CONTINUOUS_COVARIATES_PROCESSED + STATIC_COLS\n",
    ")  # Each element must correspond to a column name\n",
    "input_variables = TARGET_COL + exogenous_vars\n",
    "\n",
    "print(\n",
    "    f\"Time series params: \\nInput sequence lenght: {enc_seq_len} \\nOutput sequence lenght:\"\n",
    "    f\" {output_sequence_length} \\nStep size: {step_size}\"\n",
    ")\n",
    "\n",
    "print(f\"Model hyperparameters: \\nBatch size: {batch_size} \\nLearning rate: {lr}\")\n",
    "\n",
    "# df to patient tensor\n",
    "scaler = get_normalizing_scaler(df_train[input_variables])\n",
    "X_train, y_train = df_to_patient_tensors(\n",
    "    df_train, feature_cols=input_variables, target_col=TARGET_COL, scaler=scaler\n",
    ")\n",
    "X_valid, y_valid = df_to_patient_tensors(\n",
    "    df_valid, feature_cols=input_variables, target_col=TARGET_COL, scaler=scaler\n",
    ")\n",
    "X_test, y_test = df_to_patient_tensors(\n",
    "    df_test, feature_cols=input_variables, target_col=TARGET_COL, scaler=scaler\n",
    ")\n",
    "\n",
    "# get subsequence indices\n",
    "indices_train, num_samples_train = get_patient_indices(\n",
    "    y_train, input_seq_len=enc_seq_len, forecast_len=output_sequence_length, step_size=step_size\n",
    ")\n",
    "indices_valid, num_samples_valid = get_patient_indices(\n",
    "    y_valid, input_seq_len=enc_seq_len, forecast_len=output_sequence_length, step_size=step_size\n",
    ")\n",
    "indices_test, num_samples_test = get_patient_indices(\n",
    "    y_valid, input_seq_len=enc_seq_len, forecast_len=output_sequence_length, step_size=step_size\n",
    ")\n",
    "print(\n",
    "    f\"Number of training samples: {num_samples_train}\"\n",
    "    f\" \\nNumber of valid samples: {num_samples_valid}\"\n",
    "    f\" \\nNumber of test samples: {num_samples_test}\"\n",
    ")\n",
    "\n",
    "# create datasets\n",
    "\n",
    "dataset_train = TransformerDataset(\n",
    "    data=X_train,\n",
    "    labels=y_train,\n",
    "    indices=indices_train,\n",
    "    num_samples=num_samples_train,\n",
    "    enc_seq_len=enc_seq_len,\n",
    "    target_seq_len=output_sequence_length,\n",
    ")\n",
    "dataset_valid = TransformerDataset(\n",
    "    data=X_valid,\n",
    "    labels=y_valid,\n",
    "    indices=indices_valid,\n",
    "    num_samples=num_samples_valid,\n",
    "    enc_seq_len=enc_seq_len,\n",
    "    target_seq_len=output_sequence_length,\n",
    ")\n",
    "dataset_test = TransformerDataset(\n",
    "    data=X_test,\n",
    "    labels=y_test,\n",
    "    indices=indices_test,\n",
    "    num_samples=num_samples_test,\n",
    "    enc_seq_len=enc_seq_len,\n",
    "    target_seq_len=output_sequence_length,\n",
    ")\n",
    "\n",
    "# create dataloaders\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "# create model\n",
    "\n",
    "model = TimeSeriesTransformer(\n",
    "    input_size=len(input_variables),\n",
    "    dec_seq_len=enc_seq_len,\n",
    "    batch_first=batch_first,\n",
    "    num_predicted_features=1,\n",
    ")\n",
    "\n",
    "# create masks\n",
    "\n",
    "src_mask = generate_square_subsequent_mask(dim1=output_sequence_length, dim2=enc_seq_len)\n",
    "\n",
    "tgt_mask = generate_square_subsequent_mask(\n",
    "    dim1=output_sequence_length, dim2=output_sequence_length\n",
    ")\n",
    "\n",
    "# Criterion and optimizer and early stopping\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "early_stopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU\n"
     ]
    }
   ],
   "source": [
    "# transfer to GPU\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    print(\"Training on GPU\")\n",
    "else:\n",
    "    print(\"No GPU available, training on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "src_mask = src_mask.to(device)\n",
    "tgt_mask = tgt_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg, trg_y = next(iter(dataloader_train))\n",
    "src = src.to(device)\n",
    "trg = trg.to(device)\n",
    "trg_y = trg_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(src=src, tgt=trg, src_mask=src_mask, tgt_mask=tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('glycemic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d0dcae67a12b8b9619dd471b03512d94702322f3cad871ea227bbeeb7b51bb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
